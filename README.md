# YouTube Comments Emotion Recognition ğŸ­  

This project analyzes **YouTube video comments** and detects the **emotions** expressed in them.  
It uses the **YouTube API** to fetch comments and applies the **EmoRoBERTa model** (trained on 58k Reddit comments) to classify them into **28 emotions + neutral**.  
The system then generates **word clouds per emotion**, giving creators insights into how their content resonates emotionally.  

---

## ğŸ“¸ Screenshots  

> Replace these with your actual images  

- Web Interface Example  
![App Screenshot](assets/app_interface.png)  

- Sample Word Cloud  
![Admiration Word Cloud](assets/admiration.png)  
![Admiration Word Cloud](assets/annoyance.png)  
![Admiration Word Cloud](assets/confusion.png)  
![Admiration Word Cloud](assets/curiosity.png)  

---

## ğŸš€ Features  

- Fetches comments from any YouTube video via **YouTube API**  
- Classifies comments into **29 categories**:  
  admiration, amusement, anger, annoyance, approval, caring, confusion, curiosity, desire, disappointment, disapproval, disgust, embarrassment, excitement, fear, gratitude, grief, joy, love, nervousness, optimism, pride, realization, relief, remorse, sadness, surprise, and neutral  
- Generates **word clouds** for each detected emotion  
- Interactive **Streamlit web app** (`main.py`)  
- Helps content creators understand emotional audience feedback  

---

## ğŸ“‚ Repository Structure  

```
YouTube_Comments_Emotion_Recognition/
â”‚â”€â”€ main.py                 # Streamlit application entry point
â”‚â”€â”€ requirements.txt        # Dependencies
â”‚â”€â”€ notebooks/              # Jupyter notebooks (experimentation)
â”‚   â””â”€â”€ AI_Project.ipynb
â”‚â”€â”€ models/                 # Cloned EmoRoBERTa model
â”‚â”€â”€ screenshots/            # Images for README showcase
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation & Setup  

### 1. Clone the repository  
```bash
git clone https://github.com/ahmedfarazsyk/YouTube_Comments_Emotion_Recognition.git
cd YouTube_Comments_Emotion_Recognition
```

### 2. Install dependencies  
```bash
pip install -r requirements.txt
```

### 3. Get a YouTube API key  
- Go to [Google Cloud Console](https://console.cloud.google.com/)  
- Create a project â†’ Enable **YouTube Data API v3**  
- Generate an **API key**  
- Save the key inside a `.env` file as:  
```
API_KEY=your_api_key_here
```

### 4. Setup Hugging Face access  
```bash
huggingface-cli login
```

### 5. Clone EmoRoBERTa model  

- Make sure git-lfs is installed (https://git-lfs.com)
```bash
git lfs install
git clone https://huggingface.co/arpanghoshal/EmoRoBERTa
```

- When prompted for a password, use an access token with write permissions.
- Generate one from your settings: https://huggingface.co/settings/tokens


### 6. Run the Streamlit app  
```bash
streamlit run main.py
```

---

## ğŸ”® Future Improvements  

- Dockerize the project (current image size ~5GB makes Docker Hub push difficult)  
- Deploy on **AWS EC2 / SageMaker** for scalable access  
- Optimize model size for easier cloud deployment  

---

## ğŸ‘¨â€ğŸ’» Author  

**Ahmed Faraz Shaikh**  
[GitHub Profile](https://github.com/ahmedfarazsyk)  

